{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea969de0-2d01-4da4-9936-c8933b29e292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from functions.rename_split import copy_and_rename_files, filter_files\n",
    "from functions.load_data import collect_data, load_data\n",
    "from functions.normalize import normalize_images\n",
    "from functions.plot_images import plot_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafcdb44-53ec-4436-b96c-8c61f4ae05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "source_dir = \"img/raw/\"\n",
    "splits_dir = \"img/splits/\"\n",
    "train_dir = \"img/splits/train/\"\n",
    "test_dir = \"img/splits/test/\"\n",
    "val_dir = \"img/splits/val/\"\n",
    "\n",
    "# Create train, test, and val directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132bbdb1-b1d5-4a59-ac6f-cc1ce792b654",
   "metadata": {},
   "source": [
    "## Splitting data in 3 parts (train, test and val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2de9a-c4a3-449d-8d00-afac26a4045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize global counter\n",
    "global_counter = 1\n",
    "\n",
    "# Loop through 'yes' and 'no' folders\n",
    "for category in ['yes', 'no']:\n",
    "    category_dir = os.path.join(source_dir, category)\n",
    "    # Get list of image files\n",
    "    files = os.listdir(category_dir)\n",
    "    # Filter out files ending with 'Zone.Identifier'\n",
    "    files = filter_files(files)\n",
    "    # Split files into train, test, and val sets\n",
    "    train_files, test_val_files = train_test_split(files, test_size=0.3, random_state=42) # 60% train\n",
    "    test_files, val_files = train_test_split(test_val_files, test_size=0.5, random_state=42) # 20% test, 20% val\n",
    "    # Create category directories in train, test, and val directories if they don't exist\n",
    "    os.makedirs(os.path.join(train_dir, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, category), exist_ok=True)\n",
    "    # Copy and rename files to respective directories\n",
    "    global_counter = copy_and_rename_files(category_dir, os.path.join(train_dir, category), train_files, \"img_\", global_counter)\n",
    "    global_counter = copy_and_rename_files(category_dir, os.path.join(test_dir, category), test_files, \"img_\", global_counter)\n",
    "    global_counter = copy_and_rename_files(category_dir, os.path.join(val_dir, category), val_files, \"img_\", global_counter)\n",
    "\n",
    "print(\"Images have been copied and renamed in train, test, and val sets successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f34aed-94b9-4819-9ba3-27da5075f0f6",
   "metadata": {},
   "source": [
    "## Creating a dataframe from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c45158-d003-4ce2-aecc-3f934d8ef2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['train', 'test', 'val']\n",
    "\n",
    "data = []\n",
    "\n",
    "for split in splits:\n",
    "    for tumor_type in ['no', 'yes']:\n",
    "        data += collect_data(os.path.join(splits_dir, split, tumor_type), tumor_type, split)\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd439dc-a7c2-4332-a790-5ceaa77fe74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b7d4e8-f141-443f-b905-56765743aa12",
   "metadata": {},
   "source": [
    "## Loading and splitting data in train, test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d4b830-9e3c-464a-a5dd-bb7c53c702e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, labels = load_data(train_dir)\n",
    "X_test, y_test, _ = load_data(test_dir)\n",
    "X_val, y_val, _ = load_data(val_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba6282e-e42e-4cf4-98e0-dadc7d30587f",
   "metadata": {},
   "source": [
    "## Normalizing data for better model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc5e3b-aca5-47a7-b9e2-dc9e2a677778",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = normalize_images(X_train, target_size=(224, 224), apply_sharpening=True, apply_sobel=False)\n",
    "X_test_norm = normalize_images(X_test, target_size=(224, 224), apply_sharpening=True, apply_sobel=False)\n",
    "X_val_norm = normalize_images(X_val, target_size=(224, 224), apply_sharpening=True, apply_sobel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f53be-e500-4dcf-bb71-ab7235217343",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(X_train_norm, y_train, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aecbf45-a4bb-4107-988e-f8e5c0bccfba",
   "metadata": {},
   "source": [
    "## Model training and plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c3cbae-054c-4a88-bff5-02387761eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle VGG-16 pré-entraîné (ne pas inclure la couche dense finale)\n",
    "base_model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "\n",
    "# figer les poids du VGG\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=RMSprop(lr=1e-4),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Afficher la structure du modèle\n",
    "model.summary()\n",
    "\n",
    "# Créer un générateur d'images pour la data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.05,\n",
    "    brightness_range=[0.1, 1.5],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "# Ajuster le générateur aux données d'entraînement\n",
    "datagen.fit(X_train_norm)\n",
    "\n",
    "# Entraîner le modèle avec l'augmentation de données\n",
    "history = model.fit(datagen.flow(X_train_norm, y_train, batch_size=32),\n",
    "          epochs=10,\n",
    "          steps_per_epoch=len(X_train_norm) // 32,\n",
    "          validation_data=(X_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b5e88-488b-45be-8319-9874d11feaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a0b920-f47c-4865-b3b1-a990c4067eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    train_loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "    train_acc = history['accuracy']\n",
    "    val_acc = history['val_accuracy']\n",
    "\n",
    "# Loss\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeb2c05-9be7-4638-964c-ac2315eba94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c15cc2-e833-4828-a3da-5171db71628b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
